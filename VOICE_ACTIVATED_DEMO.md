# Voice-Activated Demo Session

## Overview

The Mentora demo session now features **voice-activated sequential reveals** with animated connections. Users start by seeing only the main title card, then can progressively reveal additional content by asking natural questions.

## How It Works

### Initial State
When users first open Mentora, they see:
- **1 visible object**: "Mentora - AI-Powered Tutoring Platform" (main title)
- **7 hidden objects**: Pre-loaded but invisible, ready for instant reveal

### Voice Triggers

#### Trigger 1: "What are you?"
**Phrases that work:**
- "What are you?"
- "Who are you?"
- "Tell me about yourself"
- "What is Mentora?"
- "Tell me about Mentora"
- "Describe yourself"
- "What do you do?"

**Reveals (3 objects):**
1. **Architecture Overview** - Full-stack architecture diagram
2. **Tech Stack** - Complete technology stack
3. **How It Works** - User flow pipeline

**Visual Effect:**
- Objects appear instantly (no delay - they're pre-loaded)
- Animated connections draw from Main Title â†’ each revealed object
- Camera smoothly pans to show all 4 objects together

#### Trigger 2: "What are your features?"
**Phrases that work:**
- "What features?"
- "What are your features?"
- "What can you do?"
- "Show me features"
- "Your capabilities"
- "What capabilities?"
- "Show me what you can do"
- "Tell me your features"

**Reveals (4 objects):**
1. **Key Features** - Voice, AI brains, canvas, MCP tools
2. **Use Cases** - Math, Biology, Code, Design examples
3. **Teaching Modes** - Socratic vs Direct modes
4. **Try It Now!** - Getting started instructions

**Visual Effect:**
- Objects appear instantly
- Animated connections draw from Main Title â†’ each revealed object
- Camera pans to show expanded view with all objects

## Technical Architecture

### File Structure

```
apps/web/
â”œâ”€â”€ types/index.ts                    # Added hidden & demoGroup properties
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ canvas-stage.tsx             # Filters hidden objects, uses voice handler
â”‚   â””â”€â”€ session-initializer.tsx      # Marks 7 of 8 objects as hidden
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ use-demo-voice-handler.ts    # NEW: Detects voice triggers
â””â”€â”€ lib/
    â””â”€â”€ session-store.ts             # Added revealDemoObjects action
```

### Data Flow

```
1. User asks question via voice/text
   â†“
2. Message added to session store
   â†“
3. useDemoVoiceHandler detects trigger phrase
   â†“
4. revealDemoObjects() action called
   â†“
5. Objects marked as hidden: false
   â†“
6. Connections created from source to targets
   â†“
7. canvas-stage filters and renders visible objects
   â†“
8. User sees instant reveal with connections
```

## Implementation Details

### CanvasObject Type Extensions

```typescript
type CanvasObject = {
  // ... existing properties
  hidden?: boolean;  // For voice-activated reveals
  demoGroup?: 'intro' | 'architecture' | 'features';  // Grouping
}
```

### Demo Groups

| Group | Objects | Trigger |
|-------|---------|---------|
| **intro** | Main Title | Always visible |
| **architecture** | Architecture, Tech Stack, How It Works | "What are you?" |
| **features** | Key Features, Use Cases, Teaching Modes, Try It Now | "What are your features?" |

### Session Store Actions

**revealDemoObjects(sessionId, demoGroup, sourceObjectId?)**
- Finds all objects in the specified demoGroup that are hidden
- Sets `hidden: false` on each object
- If sourceObjectId provided, creates connections from source to each revealed object
- Connections use 'east' anchor on source, 'west' anchor on targets

### Voice Handler Hook

**useDemoVoiceHandler(sessionId)**
- Listens for new messages in the session
- Detects trigger phrases in user messages
- Prevents duplicate reveals with internal tracking
- Automatically finds source object for connections
- Logs reveals to console for debugging

## User Experience

### Demo Flow

```
ðŸ“± App loads
   â†’ User sees: [Main Title]

ðŸŽ¤ "What are you?"
   â†’ AI responds with explanation
   â†’ Objects appear: [Architecture] [Tech Stack] [How It Works]
   â†’ Connections draw from Main Title
   â†’ Camera pans to show all 4 objects

ðŸŽ¤ "What are your features?"
   â†’ AI responds with capabilities
   â†’ Objects appear: [Features] [Use Cases] [Modes] [Try It Now]
   â†’ Connections draw from Main Title
   â†’ Camera expands to show all 8 objects

âœ… Complete demo visible
   â†’ User can explore, zoom, pan
   â†’ All 8 objects now interactive
```

### Benefits

âœ… **Instant reveals** - No backend API calls needed
âœ… **Natural interaction** - Voice-activated, conversational
âœ… **Visual storytelling** - Connections show relationships
âœ… **Professional animations** - Smooth camera movements
âœ… **Flexible triggers** - Multiple phrases work for each reveal
âœ… **Prevents duplicates** - Each group only reveals once
âœ… **Seamless integration** - Works with existing voice system

## Customization

### Adding New Trigger Phrases

Edit `apps/web/hooks/use-demo-voice-handler.ts`:

```typescript
const architectureTriggers = [
  // Add new phrases here
  'explain your architecture',
  'how are you built',
];

const featureTriggers = [
  // Add new phrases here
  'what do you offer',
  'your functionalities',
];
```

### Adding New Demo Groups

1. Add new group to type in `types/index.ts`:
```typescript
demoGroup?: 'intro' | 'architecture' | 'features' | 'advanced';
```

2. Mark objects in `session-initializer.tsx`:
```typescript
hidden: true,
demoGroup: 'advanced',
```

3. Add trigger detection in `use-demo-voice-handler.ts`:
```typescript
if (lowerText.includes('advanced features')) {
  return 'advanced';
}
```

4. Reveal on trigger:
```typescript
revealDemoObjects(sessionId, 'advanced', sourceObject.id);
```

## Debugging

### Console Logs

When a trigger is detected, you'll see:
```
ðŸŽ¯ Demo trigger detected: "architecture" - revealing objects
```

### Checking Object State

In React DevTools or browser console:
```javascript
// Get session store
const store = useSessionStore.getState();

// Check canvas objects
const objects = store.canvasObjects[sessionId];

// Find hidden objects
objects.filter(obj => obj.hidden);

// Find revealed objects
objects.filter(obj => !obj.hidden);

// Check demo groups
objects.map(obj => ({ label: obj.label, hidden: obj.hidden, group: obj.demoGroup }));
```

### Testing Triggers

You can test triggers without voice by:
1. Opening the prompt bar
2. Typing trigger phrases manually
3. Watching for reveals in the canvas

## Future Enhancements

Potential improvements:

- [ ] Add animation delays between reveals (stagger effect)
- [ ] Add sound effects on reveal
- [ ] Highlight newly revealed objects briefly
- [ ] Add third trigger phrase for "advanced features"
- [ ] Store revealed state in session for persistence
- [ ] Add "reset demo" button to hide objects again
- [ ] Track analytics on which triggers users use most
- [ ] Add visual hint showing what questions to ask next

---

**Status**: âœ… Fully implemented and ready for hackathon demo
**Last Updated**: 2025-10-26
